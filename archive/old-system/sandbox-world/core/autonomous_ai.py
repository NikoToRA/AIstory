#!/usr/bin/env python3
"""
ğŸ¤– Autonomous AI Engine
ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒç‹¬è‡ªã®æ„æ€æ±ºå®šã‚’è¡Œã†è‡ªå¾‹è¡Œå‹•ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import random
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import os

@dataclass
class ActionOption:
    """è¡Œå‹•é¸æŠè‚¢"""
    id: str
    name: str
    description: str
    energy_cost: int  # 1-10
    emotional_reward: float  # -1.0 to 1.0
    social_impact: float  # -1.0 to 1.0 (ä»–è€…ã¸ã®å½±éŸ¿)
    prerequisites: List[str]
    personality_alignment: Dict[str, float]  # æ€§æ ¼ç‰¹æ€§ã¨ã®è¦ªå’Œæ€§

@dataclass
class CharacterState:
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç¾åœ¨çŠ¶æ…‹"""
    energy: int  # 0-100
    mood: float  # -1.0 to 1.0
    stress: int  # 0-100
    social_battery: int  # 0-100 (ç¤¾äº¤çš„ã‚¨ãƒãƒ«ã‚®ãƒ¼)
    current_goal: str
    active_emotions: List[str]
    recent_memories: List[Dict[str, Any]]

class AutonomousAI:
    """è‡ªå¾‹è¡Œå‹•AIã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, anthropic_api_key: Optional[str] = None):
        self.api_key = anthropic_api_key or os.getenv('ANTHROPIC_API_KEY')
        self.action_templates = self._initialize_action_templates()
        self.decision_history = []
        self.context_memory = {}
        
    def _initialize_action_templates(self) -> Dict[str, ActionOption]:
        """è¡Œå‹•ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’åˆæœŸåŒ–"""
        actions = {}
        
        # ç¤¾äº¤çš„è¡Œå‹•
        actions["approach_friend"] = ActionOption(
            id="approach_friend",
            name="å‹é”ã«è©±ã—ã‹ã‘ã‚‹",
            description="è¿‘ãã«ã„ã‚‹å‹é”ã«è‡ªåˆ†ã‹ã‚‰å£°ã‚’ã‹ã‘ã‚‹",
            energy_cost=2,
            emotional_reward=0.4,
            social_impact=0.3,
            prerequisites=["friendship_level >= 20"],
            personality_alignment={"helpfulness": 0.8, "charisma_level": 0.6}
        )
        
        actions["help_classmate"] = ActionOption(
            id="help_classmate",
            name="ã‚¯ãƒ©ã‚¹ãƒ¡ã‚¤ãƒˆã‚’åŠ©ã‘ã‚‹",
            description="å›°ã£ã¦ã„ã‚‹äººã‚’è¦‹ã¤ã‘ã¦æ‰‹åŠ©ã‘ã™ã‚‹",
            energy_cost=4,
            emotional_reward=0.7,
            social_impact=0.5,
            prerequisites=["someone_needs_help"],
            personality_alignment={"helpfulness": 0.9, "curiosity_level": 0.4}
        )
        
        actions["start_conversation"] = ActionOption(
            id="start_conversation",
            name="æ–°ã—ã„è©±é¡Œã‚’æŒ¯ã‚‹",
            description="é¢ç™½ã„è©±é¡Œã‚„æœ€è¿‘ã®å‡ºæ¥äº‹ã«ã¤ã„ã¦è©±ã—å§‹ã‚ã‚‹",
            energy_cost=3,
            emotional_reward=0.3,
            social_impact=0.4,
            prerequisites=["social_battery >= 30"],
            personality_alignment={"charisma_level": 0.7, "humor_level": 0.5}
        )
        
        # å­¦ç¿’ãƒ»æˆé•·è¡Œå‹•
        actions["study_quietly"] = ActionOption(
            id="study_quietly",
            name="é™ã‹ã«å‹‰å¼·ã™ã‚‹",
            description="ä¸€äººã§é›†ä¸­ã—ã¦å‹‰å¼·ã«å–ã‚Šçµ„ã‚€",
            energy_cost=6,
            emotional_reward=0.2,
            social_impact=-0.1,
            prerequisites=["test_approaching"],
            personality_alignment={"perfectionism": 0.8, "self_awareness": 0.6}
        )
        
        actions["practice_hobby"] = ActionOption(
            id="practice_hobby",
            name="è¶£å‘³ã®ç·´ç¿’",
            description="ãƒ€ãƒ³ã‚¹ã‚„ç‰¹æŠ€ã®ç·´ç¿’ã‚’ã™ã‚‹",
            energy_cost=5,
            emotional_reward=0.6,
            social_impact=0.1,
            prerequisites=["free_time"],
            personality_alignment={"curiosity_level": 0.7}
        )
        
        # æ„Ÿæƒ…ç®¡ç†è¡Œå‹•
        actions["take_break"] = ActionOption(
            id="take_break",
            name="ä¼‘æ†©ã™ã‚‹",
            description="ç–²ã‚ŒãŸã¨ãã«å°‘ã—ä¼‘ã‚€",
            energy_cost=-3,  # ã‚¨ãƒãƒ«ã‚®ãƒ¼å›å¾©
            emotional_reward=0.2,
            social_impact=0.0,
            prerequisites=["energy < 30 OR stress > 60"],
            personality_alignment={"self_awareness": 0.8}
        )
        
        actions["seek_advice"] = ActionOption(
            id="seek_advice",
            name="ç›¸è«‡ã™ã‚‹",
            description="ä¿¡é ¼ã§ãã‚‹äººã«æ‚©ã¿ã‚’ç›¸è«‡ã™ã‚‹",
            energy_cost=3,
            emotional_reward=0.5,
            social_impact=0.2,
            prerequisites=["stress > 50", "trusted_friend_available"],
            personality_alignment={"trust": 0.8, "openness": 0.6}
        )
        
        # æ¢ç´¢ãƒ»å†’é™ºè¡Œå‹•
        actions["explore_school"] = ActionOption(
            id="explore_school",
            name="å­¦æ ¡æ¢ç´¢",
            description="æ™®æ®µè¡Œã‹ãªã„å ´æ‰€ã‚’æ¢ç´¢ã—ã¦ã¿ã‚‹",
            energy_cost=4,
            emotional_reward=0.4,
            social_impact=0.1,
            prerequisites=["curiosity_level >= 70"],
            personality_alignment={"curiosity_level": 0.9, "adventurousness": 0.7}
        )
        
        return actions
    
    def make_autonomous_decision(self, character_id: str, character_data: Dict[str, Any], 
                               current_state: CharacterState, 
                               world_context: Dict[str, Any]) -> Dict[str, Any]:
        """è‡ªå¾‹çš„ãªæ„æ€æ±ºå®šã‚’å®Ÿè¡Œ"""
        
        # 1. åˆ©ç”¨å¯èƒ½ãªè¡Œå‹•é¸æŠè‚¢ã‚’ç”Ÿæˆ
        available_actions = self._get_available_actions(
            character_data, current_state, world_context
        )
        
        if not available_actions:
            return self._default_action(character_id, current_state)
        
        # 2. å„è¡Œå‹•ã®è©•ä¾¡å€¤ã‚’è¨ˆç®—
        action_scores = {}
        for action_id, action in available_actions.items():
            score = self._evaluate_action(
                action, character_data, current_state, world_context
            )
            action_scores[action_id] = score
        
        # 3. æœ€é©è¡Œå‹•ã‚’é¸æŠï¼ˆç¢ºç‡çš„ï¼‰
        chosen_action_id = self._select_action_probabilistically(action_scores)
        chosen_action = available_actions[chosen_action_id]
        
        # 4. AIæ¨è«–ã«ã‚ˆã‚‹è¡Œå‹•è©³ç´°åŒ–ï¼ˆClaude APIä½¿ç”¨ï¼‰
        action_details = self._enhance_action_with_ai(
            character_id, character_data, chosen_action, current_state, world_context
        )
        
        # 5. æ±ºå®šçµæœã‚’è¨˜éŒ²
        decision_result = {
            "character_id": character_id,
            "timestamp": datetime.now(),
            "chosen_action": chosen_action_id,
            "action_details": action_details,
            "reasoning": action_details.get("reasoning", ""),
            "expected_outcomes": action_details.get("expected_outcomes", {}),
            "state_before": current_state.__dict__.copy()
        }
        
        self.decision_history.append(decision_result)
        
        return decision_result
    
    def _get_available_actions(self, character_data: Dict, state: CharacterState, 
                             world_context: Dict) -> Dict[str, ActionOption]:
        """ç¾åœ¨åˆ©ç”¨å¯èƒ½ãªè¡Œå‹•é¸æŠè‚¢ã‚’å–å¾—"""
        available = {}
        
        for action_id, action in self.action_templates.items():
            if self._check_prerequisites(action.prerequisites, character_data, state, world_context):
                available[action_id] = action
        
        return available
    
    def _check_prerequisites(self, prerequisites: List[str], character_data: Dict, 
                           state: CharacterState, world_context: Dict) -> bool:
        """å‰ææ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯"""
        for prereq in prerequisites:
            if not self._evaluate_condition(prereq, character_data, state, world_context):
                return False
        return True
    
    def _evaluate_condition(self, condition: str, character_data: Dict, 
                          state: CharacterState, world_context: Dict) -> bool:
        """æ¡ä»¶ã‚’è©•ä¾¡"""
        try:
            # å‹•çš„æ¡ä»¶è©•ä¾¡
            if ">=" in condition:
                var, threshold = condition.split(" >= ")
                value = self._get_variable_value(var.strip(), character_data, state, world_context)
                return value >= float(threshold)
            elif "<" in condition:
                var, threshold = condition.split(" < ")
                value = self._get_variable_value(var.strip(), character_data, state, world_context)
                return value < float(threshold)
            elif ">" in condition:
                var, threshold = condition.split(" > ")
                value = self._get_variable_value(var.strip(), character_data, state, world_context)
                return value > float(threshold)
            elif condition in ["someone_needs_help", "trusted_friend_available", "free_time", "test_approaching"]:
                return world_context.get(condition, False)
            else:
                return True
        except:
            return False
    
    def _get_variable_value(self, var_name: str, character_data: Dict, 
                          state: CharacterState, world_context: Dict) -> float:
        """å¤‰æ•°å€¤ã‚’å–å¾—"""
        if var_name in ["energy", "stress", "social_battery"]:
            return getattr(state, var_name)
        elif var_name == "friendship_level":
            return world_context.get("average_friendship_level", 30)
        elif var_name in character_data.get("personality_growth", {}):
            return character_data["personality_growth"][var_name]
        else:
            return 0
    
    def _evaluate_action(self, action: ActionOption, character_data: Dict, 
                        state: CharacterState, world_context: Dict) -> float:
        """è¡Œå‹•ã®è©•ä¾¡å€¤ã‚’è¨ˆç®—"""
        score = 0.0
        
        # 1. æ€§æ ¼ç‰¹æ€§ã¨ã®è¦ªå’Œæ€§ (40%)
        personality_score = 0.0
        personality_growth = character_data.get("personality_growth", {})
        
        for trait, weight in action.personality_alignment.items():
            trait_value = personality_growth.get(trait, 50) / 100.0
            personality_score += trait_value * weight
        
        if action.personality_alignment:
            personality_score /= len(action.personality_alignment)
        
        score += personality_score * 0.4
        
        # 2. ç¾åœ¨çŠ¶æ…‹ã¨ã®é©åˆæ€§ (30%)
        state_score = 0.0
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚³ã‚¹ãƒˆã¨ç¾åœ¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®é–¢ä¿‚
        if action.energy_cost <= state.energy:
            state_score += 0.5
        else:
            state_score -= 0.3  # ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£
        
        # æ°—åˆ†ã¨è¡Œå‹•ã®æ„Ÿæƒ…å ±é…¬ã®é–¢ä¿‚
        if state.mood < 0 and action.emotional_reward > 0:
            state_score += 0.3  # æ°—åˆ†æ”¹å–„è¡Œå‹•ã«ãƒœãƒ¼ãƒŠã‚¹
        
        # ã‚¹ãƒˆãƒ¬ã‚¹ã¨ç¤¾äº¤è¡Œå‹•ã®é–¢ä¿‚
        if state.stress > 60 and action.social_impact > 0.3:
            state_score -= 0.2  # é«˜ã‚¹ãƒˆãƒ¬ã‚¹æ™‚ã¯ç¤¾äº¤è¡Œå‹•ã‚’é¿ã‘ãŒã¡
        
        score += state_score * 0.3
        
        # 3. æœŸå¾…ã•ã‚Œã‚‹å ±é…¬ (20%)
        reward_score = (action.emotional_reward + 1) / 2  # -1~1 ã‚’ 0~1 ã«å¤‰æ›
        score += reward_score * 0.2
        
        # 4. ç¤¾ä¼šçš„å½±éŸ¿ã®å¥½ã¾ã—ã• (10%)
        social_score = 0.5  # ä¸­æ€§
        if action.social_impact > 0:
            # ç¤¾äº¤çš„ã‚­ãƒ£ãƒ©ã¯ç¤¾ä¼šçš„å½±éŸ¿ã‚’å¥½ã‚€
            charisma = personality_growth.get("charisma_level", 50) / 100.0
            social_score = 0.5 + (action.social_impact * charisma * 0.5)
        
        score += social_score * 0.1
        
        return max(0.0, min(1.0, score))
    
    def _select_action_probabilistically(self, action_scores: Dict[str, float]) -> str:
        """ç¢ºç‡çš„ã«è¡Œå‹•ã‚’é¸æŠ"""
        if not action_scores:
            return "take_break"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¡Œå‹•
        
        # ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹é–¢æ•°ã§ç¢ºç‡åˆ†å¸ƒã‚’è¨ˆç®—
        scores = np.array(list(action_scores.values()))
        temperatures = 2.0  # æ¢ç´¢æ€§ã®èª¿æ•´
        
        exp_scores = np.exp(scores / temperatures)
        probabilities = exp_scores / np.sum(exp_scores)
        
        # ç¢ºç‡çš„é¸æŠ
        actions = list(action_scores.keys())
        chosen_index = np.random.choice(len(actions), p=probabilities)
        
        return actions[chosen_index]
    
    def _enhance_action_with_ai(self, character_id: str, character_data: Dict, 
                              action: ActionOption, state: CharacterState, 
                              world_context: Dict) -> Dict[str, Any]:
        """AIæ¨è«–ã§è¡Œå‹•ã‚’è©³ç´°åŒ–"""
        
        # Claude APIãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯AIæ¨è«–ã‚’å®Ÿè¡Œ
        if self.api_key:
            try:
                return self._call_claude_for_action_enhancement(
                    character_id, character_data, action, state, world_context
                )
            except Exception as e:
                print(f"AI enhancement failed: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®è©³ç´°åŒ–
        return self._rule_based_enhancement(character_id, character_data, action, state)
    
    def _call_claude_for_action_enhancement(self, character_id: str, character_data: Dict,
                                          action: ActionOption, state: CharacterState,
                                          world_context: Dict) -> Dict[str, Any]:
        """Claude APIã‚’å‘¼ã³å‡ºã—ã¦è¡Œå‹•ã‚’è©³ç´°åŒ–"""
        
        import requests
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã®è¦ç´„
        character_summary = {
            "name": character_data.get("character_name", character_id),
            "personality": character_data.get("personality_growth", {}),
            "current_mood": state.mood,
            "energy": state.energy,
            "recent_goal": state.current_goal
        }
        
        prompt = f"""
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€Œ{character_summary['name']}ã€ãŒã€Œ{action.name}ã€ã¨ã„ã†è¡Œå‹•ã‚’å–ã‚ã†ã¨ã—ã¦ã„ã¾ã™ã€‚
        
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±:
        {json.dumps(character_summary, ensure_ascii=False, indent=2)}
        
        é¸æŠã—ãŸè¡Œå‹•:
        - åå‰: {action.name}
        - èª¬æ˜: {action.description}
        
        ä»¥ä¸‹ã®å½¢å¼ã§JSONã‚’è¿”ã—ã¦ãã ã•ã„:
        {{
            "dialogue": "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒè¨€ã„ãã†ãªã‚»ãƒªãƒ•",
            "internal_thought": "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å¿ƒã®å£°",
            "specific_actions": ["å…·ä½“çš„ãªè¡Œå‹•1", "å…·ä½“çš„ãªè¡Œå‹•2"],
            "reasoning": "ãªãœã“ã®è¡Œå‹•ã‚’é¸ã‚“ã ã‹ã®ç†ç”±",
            "expected_outcomes": {{
                "emotional_change": "æœŸå¾…ã•ã‚Œã‚‹æ„Ÿæƒ…å¤‰åŒ–",
                "relationship_impact": "ä»–è€…ã¸ã®å½±éŸ¿äºˆæ¸¬"
            }}
        }}
        """
        
        headers = {
            'Content-Type': 'application/json',
            'x-api-key': self.api_key
        }
        
        data = {
            "model": "claude-3-haiku-20240307",  # é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆç‰ˆ
            "max_tokens": 1000,
            "messages": [{"role": "user", "content": prompt}]
        }
        
        response = requests.post(
            'https://api.anthropic.com/v1/messages',
            headers=headers,
            json=data
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result['content'][0]['text']
            
            # JSONã‚’æŠ½å‡º
            if '```json' in content:
                json_start = content.find('```json') + 7
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
            
            return json.loads(content)
        else:
            raise Exception(f"API call failed: {response.status_code}")
    
    def _rule_based_enhancement(self, character_id: str, character_data: Dict,
                              action: ActionOption, state: CharacterState) -> Dict[str, Any]:
        """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®è¡Œå‹•è©³ç´°åŒ–ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        
        character_name = character_data.get("character_name", character_id)
        personality = character_data.get("personality_growth", {})
        
        # ãƒãƒ£ãƒƒãƒ”ãƒ¼ã¡ã‚ƒã‚“ã®ç‰¹å¾´çš„ãªã‚»ãƒªãƒ•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨
        dialogue_templates = {
            "approach_friend": [
                "ãŠã¯ã‚ˆã€œâ™ª ä»Šæ—¥ã‚‚ä¸€æ—¥ãŒã‚“ã°ã‚ã†ã­ã€œ",
                "ã‚ã€{}ã¡ã‚ƒã‚“ï¼ã¡ã‚‡ã£ã¨è©±ã•ãªã„ï¼Ÿ",
                "ã¿ã‚“ãªã€œâ™ª ä½•ã—ã¦ã‚‹ã®ã€œï¼Ÿ"
            ],
            "help_classmate": [
                "å¤§ä¸ˆå¤«ï¼Ÿä½•ã‹æ‰‹ä¼ãˆã‚‹ã“ã¨ã‚ã‚‹ã‚ˆã€œâ™ª",
                "å›°ã£ã¦ã‚‹ãªã‚‰èã„ã¦ã‚ˆã€œï¼ç§ãŒä½•ã¨ã‹ã™ã‚‹ã‹ã‚‰ã€œ",
                "ä¸€ç·’ã«ã‚„ã‚ã†ã‚ˆã€œâ™ª ä¸€äººã‚ˆã‚Šæ¥½ã—ã„ã—ã€œ"
            ],
            "start_conversation": [
                "ãã†ã„ãˆã°ã•ã€œã€ã“ã®å‰ã®ãƒ†ã‚¹ãƒˆã©ã†ã ã£ãŸï¼Ÿ",
                "ä»Šåº¦ã®æ–‡åŒ–ç¥­ã€ä½•ã‚„ã‚‹äºˆå®šã€œï¼Ÿ",
                "ã‚ï¼ãã‚Œé¢ç™½ãã†ã˜ã‚ƒã‚“ã€œâ™ª"
            ]
        }
        
        dialogue = random.choice(
            dialogue_templates.get(action.id, ["ãˆãƒ¼ã£ã¨ã­ã€œ..."])
        )
        
        return {
            "dialogue": dialogue,
            "internal_thought": f"ä»Šæ—¥ã¯{action.description}ã—ã¦ã¿ã‚ˆã†â™ª",
            "specific_actions": [action.description],
            "reasoning": f"{character_name}ã‚‰ã—ã„è‡ªç„¶ãªè¡Œå‹•é¸æŠ",
            "expected_outcomes": {
                "emotional_change": "ãƒã‚¸ãƒ†ã‚£ãƒ–ãªæ°—åˆ†å‘ä¸Š",
                "relationship_impact": "å‹å¥½çš„ãªé–¢ä¿‚ä¿ƒé€²"
            }
        }
    
    def _default_action(self, character_id: str, state: CharacterState) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¡Œå‹•ï¼ˆä½•ã‚‚ç‰¹åˆ¥ãªã“ã¨ã‚’ã—ãªã„ï¼‰"""
        return {
            "character_id": character_id,
            "timestamp": datetime.now(),
            "chosen_action": "observe",
            "action_details": {
                "dialogue": "ã†ãƒ¼ã‚“ã€ä½•ã—ã‚ˆã†ã‹ãªã€œ",
                "internal_thought": "ç‰¹ã«ã‚„ã‚‹ã“ã¨ãªã„ã‹ã‚‚...",
                "specific_actions": ["å‘¨ã‚Šã‚’è¦³å¯Ÿã™ã‚‹"],
                "reasoning": "é©åˆ‡ãªè¡Œå‹•ãŒè¦‹ã¤ã‹ã‚‰ãªã„",
                "expected_outcomes": {
                    "emotional_change": "ç‰¹ã«ãªã—",
                    "relationship_impact": "å¤‰åŒ–ãªã—"
                }
            },
            "state_before": state.__dict__.copy()
        }
    
    def update_character_state_from_action(self, state: CharacterState, 
                                         action_result: Dict[str, Any]) -> CharacterState:
        """è¡Œå‹•çµæœã‹ã‚‰ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼çŠ¶æ…‹ã‚’æ›´æ–°"""
        action_id = action_result.get("chosen_action")
        
        if action_id in self.action_templates:
            action = self.action_templates[action_id]
            
            # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å¤‰åŒ–
            new_energy = max(0, min(100, state.energy - action.energy_cost))
            
            # æ°—åˆ†ã®å¤‰åŒ–
            mood_change = action.emotional_reward * 0.3
            new_mood = max(-1.0, min(1.0, state.mood + mood_change))
            
            # ç¤¾äº¤ãƒãƒƒãƒ†ãƒªãƒ¼ã®å¤‰åŒ–
            social_change = int(action.social_impact * 10)
            new_social_battery = max(0, min(100, state.social_battery + social_change))
            
            # æ–°ã—ã„çŠ¶æ…‹ã‚’ä½œæˆ
            updated_state = CharacterState(
                energy=new_energy,
                mood=new_mood,
                stress=max(0, state.stress - 5),  # è¡Œå‹•ã«ã‚ˆã‚Šã‚¹ãƒˆãƒ¬ã‚¹è»½æ¸›
                social_battery=new_social_battery,
                current_goal=state.current_goal,
                active_emotions=state.active_emotions,
                recent_memories=state.recent_memories + [action_result]
            )
            
            return updated_state
        
        return state

# ä½¿ç”¨ä¾‹ãƒ»ãƒ†ã‚¹ãƒˆç”¨
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
    test_character_data = {
        "character_name": "ç›¸ç”°èŒ¶å­",
        "personality_growth": {
            "helpfulness": 95,
            "curiosity_level": 90,
            "charisma_level": 90,
            "humor_level": 85
        }
    }
    
    test_state = CharacterState(
        energy=75,
        mood=0.3,
        stress=20,
        social_battery=80,
        current_goal="å‹é”ã¨ã®é–¢ä¿‚ã‚’æ·±ã‚ã‚‹",
        active_emotions=["happy", "energetic"],
        recent_memories=[]
    )
    
    test_world_context = {
        "someone_needs_help": True,
        "trusted_friend_available": True,
        "free_time": True,
        "average_friendship_level": 60
    }
    
    # è‡ªå¾‹AIã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œ
    ai_engine = AutonomousAI()
    
    decision = ai_engine.make_autonomous_decision(
        "chappie", test_character_data, test_state, test_world_context
    )
    
    print(f"é¸æŠã•ã‚ŒãŸè¡Œå‹•: {decision['chosen_action']}")
    print(f"ã‚»ãƒªãƒ•: {decision['action_details']['dialogue']}")
    print(f"æ¨è«–: {decision['action_details']['reasoning']}")
    
    # çŠ¶æ…‹æ›´æ–°ãƒ†ã‚¹ãƒˆ
    updated_state = ai_engine.update_character_state_from_action(test_state, decision)
    print(f"\\næ›´æ–°å¾Œã‚¨ãƒãƒ«ã‚®ãƒ¼: {updated_state.energy}")
    print(f"æ›´æ–°å¾Œæ°—åˆ†: {updated_state.mood:.2f}")